{"cells":[{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":289,"status":"ok","timestamp":1657808861803,"user":{"displayName":"長曽我部崇","userId":"09520727656816344536"},"user_tz":-540},"id":"m6md4V9lc77A","outputId":"c79da3c7-0f9a-4649-e8d6-7c63d82e7c7b"},"outputs":[],"source":["# %cd /content/drive/My Drive/ColabNotebooks/mnist\n","# %ls"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1657808862102,"user":{"displayName":"長曽我部崇","userId":"09520727656816344536"},"user_tz":-540},"id":"tZzoAenebOYI","outputId":"1b291681-bd60-4b6b-82cc-44efcf2debff"},"outputs":[{"name":"stdout","output_type":"stream","text":["PyTorch Version:  1.12.0+cu116\n","Torchvision Version:  0.13.0+cu116\n"]}],"source":["from __future__ import print_function\n","from __future__ import division\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","print(\"PyTorch Version: \",torch.__version__)\n","print(\"Torchvision Version: \",torchvision.__version__)"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1657808862102,"user":{"displayName":"長曽我部崇","userId":"09520727656816344536"},"user_tz":-540},"id":"jGnoVfyYbOYL"},"outputs":[],"source":["# Top level data directory. Here we assume the format of the directory conforms\n","#   to the ImageFolder structure\n","data_dir = \"./data/itigo3class\"\n","# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n","model_name = \"resnet\"\n","# Number of classes in the dataset\n","num_classes = 3\n","# Batch size for training (change depending on how much memory you have)\n","batch_size = 32\n","# Number of epochs to train for\n","num_epochs = 30\n","# Flag for feature extracting. When False, we finetune the whole model,\n","#   when True we only update the reshaped layer params\n","feature_extract = False"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":396,"status":"ok","timestamp":1657808862494,"user":{"displayName":"長曽我部崇","userId":"09520727656816344536"},"user_tz":-540},"id":"6X_zSZN6bOYM"},"outputs":[],"source":["def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n","    since = time.time()\n","\n","    val_acc_history = []\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    # Get model outputs and calculate loss\n","                    # Special case for inception because in training it has an auxiliary output. In train\n","                    #   mode we calculate the loss by summing the final output and the auxiliary output\n","                    #   but in testing we only consider the final output.\n","                    if is_inception and phase == 'train':\n","                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n","                        outputs, aux_outputs = model(inputs)\n","                        loss1 = criterion(outputs, labels)\n","                        loss2 = criterion(aux_outputs, labels)\n","                        loss = loss1 + 0.4*loss2\n","                    else:\n","                        outputs = model(inputs)\n","                        loss = criterion(outputs, labels)\n","\n","                    _, preds = torch.max(outputs, 1)\n","\n","                    ###########\n","                    # 追加\n","                    ###########\n","                    # print(\"preds\")\n","                    # print(preds)\n","                    # print(\"label\")\n","                    # print(labels)\n","\n","\n","                    ###########\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","                \n","\n","            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","            #######\n","            # 追加\n","            #######\n","            if phase == 'val':\n","                print('{} / {} = Acc: {:.4f}'.format(running_corrects.double(), len(dataloaders[phase].dataset), epoch_acc))\n","\n","                # print(preds)\n","\n","                # print(labels.data)\n","\n","            #######\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","            if phase == 'val':\n","                val_acc_history.append(epoch_acc)\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model, val_acc_history"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1657808862494,"user":{"displayName":"長曽我部崇","userId":"09520727656816344536"},"user_tz":-540},"id":"lew0Q69TbOYO"},"outputs":[],"source":["def set_parameter_requires_grad(model, feature_extracting):\n","    if feature_extracting:\n","        for param in model.parameters():\n","            param.requires_grad = False"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1657808862495,"user":{"displayName":"長曽我部崇","userId":"09520727656816344536"},"user_tz":-540},"id":"qYJ_5jXobOYP","outputId":"50be73cc-8d1f-4305-8bc7-7aa31f9d68a3"},"outputs":[],"source":["def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n","    # Initialize these variables which will be set in this if statement. Each of these\n","    #   variables is model specific.\n","    model_ft = None\n","    input_size = 0\n","\n","    if model_name == \"resnet\":\n","        \"\"\" Resnet18\n","        \"\"\"\n","        model_ft = models.resnet18(weights='ResNet18_Weights.IMAGENET1K_V1')\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        num_ftrs = model_ft.fc.in_features\n","        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n","        input_size = 224\n","\n","    elif model_name == \"alexnet\":\n","        \"\"\" Alexnet\n","        \"\"\"\n","        model_ft = models.alexnet(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        num_ftrs = model_ft.classifier[6].in_features\n","        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n","        input_size = 224\n","\n","    elif model_name == \"vgg\":\n","        \"\"\" VGG11_bn\n","        \"\"\"\n","        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        num_ftrs = model_ft.classifier[6].in_features\n","        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n","        input_size = 224\n","\n","    elif model_name == \"squeezenet\":\n","        \"\"\" Squeezenet\n","        \"\"\"\n","        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n","        model_ft.num_classes = num_classes\n","        input_size = 224\n","\n","    elif model_name == \"densenet\":\n","        \"\"\" Densenet\n","        \"\"\"\n","        model_ft = models.densenet121(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        num_ftrs = model_ft.classifier.in_features\n","        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n","        input_size = 224\n","\n","    elif model_name == \"inception\":\n","        \"\"\" Inception v3\n","        Be careful, expects (299,299) sized images and has auxiliary output\n","        \"\"\"\n","        model_ft = models.inception_v3(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        # Handle the auxilary net\n","        num_ftrs = model_ft.AuxLogits.fc.in_features\n","        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n","        # Handle the primary net\n","        num_ftrs = model_ft.fc.in_features\n","        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n","        input_size = 299\n","\n","    else:\n","        print(\"Invalid model name, exiting...\")\n","        exit()\n","\n","    return model_ft, input_size\n","\n","# Initialize the model for this run\n","model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n","\n","# Print the model we just instantiated\n","# print(model_ft)"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1802,"status":"ok","timestamp":1657808864293,"user":{"displayName":"長曽我部崇","userId":"09520727656816344536"},"user_tz":-540},"id":"zVGslsQEbOYQ","outputId":"8f7460af-5ce6-492d-b4e6-032a58b9e13f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Initializing Datasets and Dataloaders...\n"]}],"source":["# Data augmentation and normalization for training\n","# Just normalization for validation\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(input_size),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(input_size),\n","        transforms.CenterCrop(input_size),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","print(\"Initializing Datasets and Dataloaders...\")\n","\n","# Create training and validation datasets\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n","# Create training and validation dataloaders\n","dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n","\n","# Detect if we have a GPU available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1820,"status":"ok","timestamp":1657808866106,"user":{"displayName":"長曽我部崇","userId":"09520727656816344536"},"user_tz":-540},"id":"2eD1-mVmGyaE","outputId":"cdd08b6f-c3ca-4d4f-acf4-4e158edeaf72"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4246,"status":"ok","timestamp":1657808870347,"user":{"displayName":"長曽我部崇","userId":"09520727656816344536"},"user_tz":-540},"id":"uGrtxyOmbOYQ","outputId":"e1a96393-989e-43e2-c6f8-917596b868df"},"outputs":[{"name":"stdout","output_type":"stream","text":["Params to learn:\n","\t conv1.weight\n","\t bn1.weight\n","\t bn1.bias\n","\t layer1.0.conv1.weight\n","\t layer1.0.bn1.weight\n","\t layer1.0.bn1.bias\n","\t layer1.0.conv2.weight\n","\t layer1.0.bn2.weight\n","\t layer1.0.bn2.bias\n","\t layer1.1.conv1.weight\n","\t layer1.1.bn1.weight\n","\t layer1.1.bn1.bias\n","\t layer1.1.conv2.weight\n","\t layer1.1.bn2.weight\n","\t layer1.1.bn2.bias\n","\t layer2.0.conv1.weight\n","\t layer2.0.bn1.weight\n","\t layer2.0.bn1.bias\n","\t layer2.0.conv2.weight\n","\t layer2.0.bn2.weight\n","\t layer2.0.bn2.bias\n","\t layer2.0.downsample.0.weight\n","\t layer2.0.downsample.1.weight\n","\t layer2.0.downsample.1.bias\n","\t layer2.1.conv1.weight\n","\t layer2.1.bn1.weight\n","\t layer2.1.bn1.bias\n","\t layer2.1.conv2.weight\n","\t layer2.1.bn2.weight\n","\t layer2.1.bn2.bias\n","\t layer3.0.conv1.weight\n","\t layer3.0.bn1.weight\n","\t layer3.0.bn1.bias\n","\t layer3.0.conv2.weight\n","\t layer3.0.bn2.weight\n","\t layer3.0.bn2.bias\n","\t layer3.0.downsample.0.weight\n","\t layer3.0.downsample.1.weight\n","\t layer3.0.downsample.1.bias\n","\t layer3.1.conv1.weight\n","\t layer3.1.bn1.weight\n","\t layer3.1.bn1.bias\n","\t layer3.1.conv2.weight\n","\t layer3.1.bn2.weight\n","\t layer3.1.bn2.bias\n","\t layer4.0.conv1.weight\n","\t layer4.0.bn1.weight\n","\t layer4.0.bn1.bias\n","\t layer4.0.conv2.weight\n","\t layer4.0.bn2.weight\n","\t layer4.0.bn2.bias\n","\t layer4.0.downsample.0.weight\n","\t layer4.0.downsample.1.weight\n","\t layer4.0.downsample.1.bias\n","\t layer4.1.conv1.weight\n","\t layer4.1.bn1.weight\n","\t layer4.1.bn1.bias\n","\t layer4.1.conv2.weight\n","\t layer4.1.bn2.weight\n","\t layer4.1.bn2.bias\n","\t fc.weight\n","\t fc.bias\n"]}],"source":["model_ft = model_ft.to(device)\n","\n","# Gather the parameters to be optimized/updated in this run. If we are\n","#  finetuning we will be updating all parameters. However, if we are\n","#  doing feature extract method, we will only update the parameters\n","#  that we have just initialized, i.e. the parameters with requires_grad\n","#  is True.\n","params_to_update = model_ft.parameters()\n","print(\"Params to learn:\")\n","if feature_extract:\n","    params_to_update = []\n","    for name,param in model_ft.named_parameters():\n","        if param.requires_grad == True:\n","            params_to_update.append(param)\n","            print(\"\\t\",name)\n","else:\n","    for name,param in model_ft.named_parameters():\n","        if param.requires_grad == True:\n","            print(\"\\t\",name)\n","\n","# Observe that all parameters are being optimized\n","optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34398,"status":"ok","timestamp":1657808904739,"user":{"displayName":"長曽我部崇","userId":"09520727656816344536"},"user_tz":-540},"id":"q6YXMm9-bOYR","outputId":"5e724c41-f33c-455b-8baa-33c8a88a5786"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0/29\n","----------\n","train Loss: 0.8336 Acc: 0.6098\n","val Loss: 0.7667 Acc: 0.6750\n","351.0 / 520 = Acc: 0.6750\n","\n","Epoch 1/29\n","----------\n","train Loss: 0.7479 Acc: 0.6711\n","val Loss: 0.7562 Acc: 0.6692\n","348.0 / 520 = Acc: 0.6692\n","\n","Epoch 2/29\n","----------\n","train Loss: 0.7113 Acc: 0.6769\n","val Loss: 0.6652 Acc: 0.7135\n","371.0 / 520 = Acc: 0.7135\n","\n","Epoch 3/29\n","----------\n","train Loss: 0.6964 Acc: 0.6894\n","val Loss: 0.6680 Acc: 0.7404\n","385.0 / 520 = Acc: 0.7404\n","\n","Epoch 4/29\n","----------\n","train Loss: 0.6597 Acc: 0.7105\n","val Loss: 0.6628 Acc: 0.7250\n","377.0 / 520 = Acc: 0.7250\n","\n","Epoch 5/29\n","----------\n","train Loss: 0.6682 Acc: 0.7100\n","val Loss: 0.6348 Acc: 0.7615\n","396.0 / 520 = Acc: 0.7615\n","\n","Epoch 6/29\n","----------\n","train Loss: 0.6407 Acc: 0.7239\n","val Loss: 0.6777 Acc: 0.7231\n","376.0 / 520 = Acc: 0.7231\n","\n","Epoch 7/29\n","----------\n","train Loss: 0.6206 Acc: 0.7272\n","val Loss: 0.6510 Acc: 0.7154\n","372.0 / 520 = Acc: 0.7154\n","\n","Epoch 8/29\n","----------\n","train Loss: 0.6366 Acc: 0.7253\n","val Loss: 0.6215 Acc: 0.7577\n","394.0 / 520 = Acc: 0.7577\n","\n","Epoch 9/29\n","----------\n","train Loss: 0.6063 Acc: 0.7383\n","val Loss: 0.6458 Acc: 0.7365\n","383.0 / 520 = Acc: 0.7365\n","\n","Epoch 10/29\n","----------\n","train Loss: 0.5930 Acc: 0.7459\n","val Loss: 0.6438 Acc: 0.7385\n","384.0 / 520 = Acc: 0.7385\n","\n","Epoch 11/29\n","----------\n","train Loss: 0.5972 Acc: 0.7469\n","val Loss: 0.6352 Acc: 0.7404\n","385.0 / 520 = Acc: 0.7404\n","\n","Epoch 12/29\n","----------\n","train Loss: 0.5705 Acc: 0.7498\n","val Loss: 0.6189 Acc: 0.7615\n","396.0 / 520 = Acc: 0.7615\n","\n","Epoch 13/29\n","----------\n","train Loss: 0.5638 Acc: 0.7608\n","val Loss: 0.6470 Acc: 0.7173\n","373.0 / 520 = Acc: 0.7173\n","\n","Epoch 14/29\n","----------\n","train Loss: 0.5525 Acc: 0.7593\n","val Loss: 0.6406 Acc: 0.7500\n","390.0 / 520 = Acc: 0.7500\n","\n","Epoch 15/29\n","----------\n","train Loss: 0.5622 Acc: 0.7617\n","val Loss: 0.6850 Acc: 0.7250\n","377.0 / 520 = Acc: 0.7250\n","\n","Epoch 16/29\n","----------\n","train Loss: 0.5523 Acc: 0.7598\n","val Loss: 0.6476 Acc: 0.7462\n","388.0 / 520 = Acc: 0.7462\n","\n","Epoch 17/29\n","----------\n","train Loss: 0.5181 Acc: 0.7737\n","val Loss: 0.6720 Acc: 0.7250\n","377.0 / 520 = Acc: 0.7250\n","\n","Epoch 18/29\n","----------\n","train Loss: 0.5133 Acc: 0.7852\n","val Loss: 0.6761 Acc: 0.7500\n","390.0 / 520 = Acc: 0.7500\n","\n","Epoch 19/29\n","----------\n","train Loss: 0.5028 Acc: 0.7756\n","val Loss: 0.6542 Acc: 0.7538\n","392.0 / 520 = Acc: 0.7538\n","\n","Epoch 20/29\n","----------\n","train Loss: 0.5085 Acc: 0.7848\n","val Loss: 0.6894 Acc: 0.7423\n","386.0 / 520 = Acc: 0.7423\n","\n","Epoch 21/29\n","----------\n","train Loss: 0.4835 Acc: 0.7977\n","val Loss: 0.7219 Acc: 0.7519\n","391.0 / 520 = Acc: 0.7519\n","\n","Epoch 22/29\n","----------\n","train Loss: 0.4805 Acc: 0.7876\n","val Loss: 0.7035 Acc: 0.7250\n","377.0 / 520 = Acc: 0.7250\n","\n","Epoch 23/29\n","----------\n","train Loss: 0.4813 Acc: 0.7929\n","val Loss: 0.6893 Acc: 0.7462\n","388.0 / 520 = Acc: 0.7462\n","\n","Epoch 24/29\n","----------\n","train Loss: 0.4884 Acc: 0.7943\n","val Loss: 0.6898 Acc: 0.7538\n","392.0 / 520 = Acc: 0.7538\n","\n","Epoch 25/29\n","----------\n","train Loss: 0.4613 Acc: 0.8001\n","val Loss: 0.6764 Acc: 0.7519\n","391.0 / 520 = Acc: 0.7519\n","\n","Epoch 26/29\n","----------\n","train Loss: 0.4441 Acc: 0.8198\n","val Loss: 0.7066 Acc: 0.7365\n","383.0 / 520 = Acc: 0.7365\n","\n","Epoch 27/29\n","----------\n","train Loss: 0.4328 Acc: 0.8169\n","val Loss: 0.7753 Acc: 0.7365\n","383.0 / 520 = Acc: 0.7365\n","\n","Epoch 28/29\n","----------\n","train Loss: 0.4411 Acc: 0.8020\n","val Loss: 0.8714 Acc: 0.7096\n","369.0 / 520 = Acc: 0.7096\n","\n","Epoch 29/29\n","----------\n","train Loss: 0.4393 Acc: 0.8130\n","val Loss: 0.6764 Acc: 0.7462\n","388.0 / 520 = Acc: 0.7462\n","\n","Training complete in 4m 45s\n","Best val Acc: 0.761538\n"]}],"source":["# Setup the loss fxn\n","criterion = nn.CrossEntropyLoss()\n","\n","# Train and evaluate\n","model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":477},"executionInfo":{"elapsed":1846,"status":"ok","timestamp":1657809449522,"user":{"displayName":"長曽我部崇","userId":"09520727656816344536"},"user_tz":-540},"id":"ghMEEQfBGtJ2","outputId":"0e7dead1-9d02-44d9-d50f-5e42b8dcbfc5"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 864x504 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["import pandas as pd\n","import seaborn as sn\n","\n","def val_model(model, dataloaders, optimizer):\n","    phase = 'val'\n","    nb_classes = 3\n","    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n","    model.eval()\n","    for inputs, labels in dataloaders[phase]:\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","        with torch.set_grad_enabled(phase == 'train'):\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            _, preds = torch.max(outputs, 1)\n","            # print(labels.view(-1))\n","            # print(preds.view(-1))\n","            for t_confusion_matrix, p_confusion_matrix in zip(labels.view(-1), preds.view(-1)):\n","                confusion_matrix[t_confusion_matrix.long(), p_confusion_matrix.long()] += 1\n","    \n","    confusion_matrix_numpy = confusion_matrix.to('cpu').detach().numpy().copy()\n","    df_cmx = pd.DataFrame(confusion_matrix_numpy)\n","    plt.figure(figsize = (12, 7))\n","    sn.heatmap(df_cmx, annot=True, fmt='g', cmap='Blues')\n","\n","val_model(model_ft, dataloaders_dict, optimizer_ft)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"finetuning.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.8.10 ('.shibuya': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"7bb1d15e5c17638c92650606ec1e31aed4a529ed3ac71cfef3990d0568e3fef2"}}},"nbformat":4,"nbformat_minor":0}
